{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Web Scraping with Python\n",
    "\n",
    "#### CEMFI Undergraduate Summer Internship 2021\n",
    "\n",
    "#### Instructor: Cay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Outline\n",
    "\n",
    "1. Introduction: Python and Jupyter Notebooks\n",
    "1. **Web Scraping Example 1**\n",
    "1. Web Scraping Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section overview\n",
    "\n",
    "In this part of the course we will\n",
    "\n",
    "- [Discuss the basics of web browsing and HTML](#Web-browsing-and-scraping)\n",
    "- [Scrape customer review information from hotels on Tripadvisor](#Scraping-Example:-Tripadvisor-hotels)\n",
    "    - [Step 1: Visual inspection of website](#Step-1:-Inspect-the-page-to-be-scraped)\n",
    "    - [Step 2: Send a **request** to the server](#Step-2:-Use-requests-to-receive-HTML-code)\n",
    "    - [Step 3: Parse the HTML](#Step-3:-Use-BeautifulSoup-to-read-HTML)\n",
    "    - [Step 4: Find relevant information](#Step-4:-Use-the-find-and-find_all-methods-to-extract-information-from-the-soup)\n",
    "    - [Step 5: Scale up](#Step-5:-Scale-up-(and-adjust-small-issues))\n",
    "    - [Step 6: Export data](#Step-6:-Export-the-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web browsing and scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A browser (Firefox, Safari, Chrome) renders HTML, which is the code used to design webpages.\n",
    "- To view HTML of a website, we can use the `View Page Source` tool from the browser ([show example](https://www.cemfi.es/)).\n",
    "- A lot of data is available online and we can use web scraping to obtain this information from the HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__HTML__ is what is known as a __markup language__. \n",
    "\n",
    "That is, HTML is text that has been “marked up” with tags that provide information for the interpreter (which is often a web browser). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple HTML document\n",
    "\n",
    "The simplest HTML file consists of:\n",
    "- `tags` indicating the beginning and end of the whole document.\n",
    "- and `tags` which identify a `head` and a `body` within that document. \n",
    "\n",
    "Information about the file usually goes into the `head`, whereas information that will be displayed on the screen usually goes into the `body`.\n",
    "\n",
    "**Note:** a Jupyter Notebook cell with `Markdown` type is also able to interpret HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "\n",
    "<head>\n",
    "<h1>A Simple HTML page</h1>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "\n",
    "<p>A text editor shows tags.</p>\n",
    "\n",
    "<p>But a browser knows how to read them.</p>\n",
    "    \n",
    "<p>It also knows how to read tables.</p>\n",
    "\n",
    "<table style=“width=100%”>\n",
    " <tr>\n",
    "\t<td>Madrid\n",
    "\t<td>Madrid\n",
    "\t<td>Spain\n",
    " </tr>\n",
    " <tr>\n",
    "\t<td>A Coruña\n",
    "\t<td>Galicia\n",
    "\t<td>Spain\n",
    " </tr>\n",
    "    <tr>\n",
    "\t<td>Sevilla\n",
    "\t<td>Andalucia\n",
    "\t<td>Spain\n",
    " </tr>\n",
    "  <tr>\n",
    "\t<td>Gijon\n",
    "\t<td>Asturias\n",
    "\t<td>Spain\n",
    " </tr>\n",
    "</table>\n",
    "\n",
    "</body>\n",
    "\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The internet as a source to explore experience goods\n",
    "\n",
    "For firms sellling experience goods, **reputation** is extremely valuable since this is one of the primary factors influencing customers' purchasing decisions.\n",
    "\n",
    "With the expansion of online platforms that allow consumers to rate their experiences with different businesses, the **online reputation** aspect of a firm is becoming ever more relevant.\n",
    "\n",
    "In this lecture, we focus on a particular kind of experience good, **hotels / accommodation service**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "Let's suppose our goal is to gather data on many hotel listings.\n",
    "\n",
    "Specifically, we want each hotel's **online reputation and price**.\n",
    "\n",
    "By **online reputation** I refer to the __number of customer reviews and the average rating__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we do that?\n",
    "\n",
    "One option to use the information available in an online travel website.\n",
    "\n",
    "I will use [Tripadvisor's](https://www.tripadvisor.com/Hotels-g187514-Madrid-Hotels.html) hotel booking section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: `Inspect` the page to be scraped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before writing code, it is important to have a look at website we want take information from and check its HTML structure.\n",
    "\n",
    "To access website information via Python we will need to know the HTML `tags` of the items/variables we want to scrape.\n",
    "\n",
    "My preferred way for this initial inspection is:\n",
    "- Navigate to the website you want to scrape.\n",
    "- Right-click on the item/data you are interested (e.g. reviews, ratings, etc).\n",
    "- Choose `Inspect`.\n",
    "- This brings up a windown with the `HTML` of the item that you can use to identify relevant `tags`. \n",
    "\n",
    "### Example\n",
    "\n",
    "Show the steps above on [Tripadvisor's](https://www.tripadvisor.com/Hotels-g187514-Madrid-Hotels.html) for the *name* of a hotel.\n",
    "\n",
    "The relevant HTML information to reference the name of a hotel is:\n",
    "- An **`a`** container.\n",
    "- And the attribute **`class`** with value **`property_title prominent`**\n",
    "\n",
    "**Note:** this is one option but not the only one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Use `requests` to receive HTML code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hypertext Transfer Protocol (HTTP) is designed to enable communications between clients and servers.\n",
    "\n",
    "**Example:** A client (browser) sends an HTTP request to the server and the server returns a *response* to the client. This *response* contains status information about the request and may also contain the requested content.\n",
    "\n",
    "**Remarks:** \n",
    " - We don't need to know the details of how this process works (we are not web developers).\n",
    " - We just need to know how to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requests library \n",
    "\n",
    "`Requests` is the standard library for making HTTP requests in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing `requests`\n",
    "\n",
    "We first need to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python command to install packages\n",
    "%pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we have to `import` the library to use it in the current notebook (or script if you are writing in an IDE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, in Python we do many imports\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library `requests` offers many `methods` to be used.\n",
    "\n",
    "The most common method is `get`, which indicates that you’re trying to get or retrieve data from a specified resource (that's what we want from Tripadvisor). \n",
    "\n",
    "To make a `get` request, invoke `requests.get(https://www.example......)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send a get request to Tripadvisor\n",
    "url = \"https://www.tripadvisor.com/Hotels-g187514-Madrid-Hotels.html\"\n",
    "\n",
    "# try other websites\n",
    "# Tripadvisor has changed its code, and requests does not work anymore\n",
    "# the technique taught in the next notebook (selenium) works with Tripadvisor\n",
    "#url = \"https://www.eldiario.es/\"\n",
    "\n",
    "requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what is this __response__?\n",
    "\n",
    "It is an object for inspecting the results of the request. \n",
    "\n",
    "Let's make the `request` again and store its result in a variable called *result*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the variable *`result`* to see information from our `get` request sent to Tripadvisor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status Codes\n",
    "\n",
    "The most basic information delivered by the `get` request is the **status code**, which indicates whether a specific request has been successfully completed.\n",
    "\n",
    "For example, a `200` status means that your request was successful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check status code\n",
    "result.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other status codes with different meanings.\n",
    "\n",
    "They have the structure 1xx, 2xx, 3xx, 4xx, etc.\n",
    "\n",
    "If you ever encounter anything different than 200, check [here](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes) for its meaning.\n",
    "\n",
    "**Remark:** one status code that may appear and is important to know is the `403`. \n",
    "- `403 Forbidden` indicates that the server understood the request but refuses to authorize it.\n",
    "- You may get this error because some websites have security features to prevent bots/scaping. \n",
    "\n",
    "There are ways to prevent this from happening, but they are beyond the scope of this course (one workaround is discussed [here](https://medium.com/@raiyanquaium/how-to-web-scrape-using-beautiful-soup-in-python-without-running-into-http-error-403-554875e5abed#:~:text=This%20will%20result%20in%20a,security%20features%20to%20prevent%20bots.)).\n",
    "\n",
    "**DISCLAIMER:** \n",
    "- This course does not cover the legal aspect of scraping.\n",
    "- You should check if there are legal issues before scraping any given webpage (e.g. data limits, commercial use). \n",
    "- You may get blocked if the server detects you are trying to scrape large amounts of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send a get reques and check its status code\n",
    "requests.get(\"https://www.idealista.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Use `BeautifulSoup` to read HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library for getting data out of HTML and other markup languages. \n",
    "\n",
    "As we saw, [Tripadvisor](https://www.tripadvisor.com/Hotels-g187514-Madrid-Hotels.html) displays the data we want on the screen, but does not provide a way of downloading it directly. \n",
    "\n",
    "Beautiful Soup helps us pull content from a webpage and remove the HTML markup, leaving only the information we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing `BeautifulSoup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we have to import the library in order to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that's the standard way to import BeautifulSoup\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember we saved the response of our `requests.get()` in a variable called `results`.\n",
    "\n",
    "We already discussed the **status code**, which was OK!\n",
    "\n",
    "The other crucial piece of information that the `get` request delivers is called **`content`**.\n",
    "\n",
    "For example, the content of our request is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results stores the response of requests.get() and we can see the attribute \"content\" of this response\n",
    "print(result.content[ 0 : 1000] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see it has the structure of `HTML` `tags` we discussed previously.\n",
    "\n",
    "Here is where __BeautifulSoup__ does its trick. \n",
    "\n",
    "It is able to *read* this `content` and transform it into a Python object (something Python understands).\n",
    "\n",
    "In one line of code we can accomplish that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup parses the HTML content and python now understands the object \"soup\"\n",
    "soup = BeautifulSoup(result.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print our `soup` using the `prettify` method to improve visibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the identation looks nicer and it is easier to search for what we need.\n",
    "\n",
    "We can see different attributes of our `soup`. \n",
    "\n",
    "For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the same title shown in the browser tab\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within `<>` are names of HTML `tags` (above *title* is a `tag`).\n",
    "\n",
    "In between the start of tag x `<x>` and the end tag x `</x>` is the part rendered as *text*. \n",
    "\n",
    "For any object in the `soup` the `.text` method gets rid of `tags` and outputs only the part rendered as *text*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text of soup title\n",
    "soup.title.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Use the `find` and `find_all` methods to extract information from the soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find` method returns the **first** occurrence of an element *marked* with the parameters we ask it to search for, whereas the `find_all` method returns the set of **all** such elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first element with the \"a\" tag (link to flights)\n",
    "first_a_tag = soup.find(\"a\")\n",
    "\n",
    "# all \"a\" objects on the webpage\n",
    "all_a_tags = soup.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `.find` delivers a `Tag` object, while a `.find_all` delivers an object called `ResultSet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntax of find method\n",
    "type(first_a_tag) , type(all_a_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access individual elements of a `ResultSet` with the standard Python index and slice notations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the output of find is the same as the first element of the find_all\n",
    "all_a_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_a_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the same way we loop over *lists*, we can loop over *ResultSets*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_a_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can loop over ResultSets\n",
    "for idx, value in enumerate(all_a_tags[:20]):\n",
    "    print(idx, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `.find` to get the variables we want\n",
    "\n",
    "For each hotel listed our goal is to retrieve:\n",
    "- Hotel name\n",
    "- Number of customer reviews\n",
    "- Average rating\n",
    "- Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable 1: Hotel name\n",
    "\n",
    "In Step 1 we had already discussed the `tags` with which hotel names are marked.\n",
    "\n",
    "Below is the HTML code that contains the name of the first hotel listed on the page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "<a target=\"_blank\" href=\"/Hotel_Review-g187514-d15886984-Reviews-Aloft_Madrid_Gran_Via-Madrid.html\" \n",
    "id=\"property_15886984\" class=\"property_title prominent \" data-clicksource=\"HotelName\" \n",
    "onclick=\"return false;\" dir=\"ltr\">Aloft Madrid Gran Via</a>\n",
    "\"\"\"; # the \";\" is only used to suppress output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the object that holds the hotel name starts with the tag `a` (because hotel name is clickable and has a *link* attached to it).\n",
    "\n",
    "We could try to use `soup.find(\"a\")`, but the line of code below shows that this is not enough to get what we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only one tag is usually not enough\n",
    "soup.find(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here is that there are other elements tagged with `a`, so the find method delivers the first one that it encounters.\n",
    "\n",
    "Using `find_all` isn't a good option either because even though it would get hotel names, it would also have several other elements that we are not looking for. \n",
    "\n",
    "When we want to access specific elements we need to use more precise search parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes\n",
    "\n",
    "In the HTML above, the tag `a` is what is known as a **container**.\n",
    "\n",
    "Inside a **container**, there are other objects called **attributes**, which hold **values**.\n",
    "\n",
    "For example, we can check which attributes an object has by using `.attrs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes \n",
    "soup.find(\"a\").attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the object that holds the name of a hotel, we must use an *attribute* and its *value* to narrow down our search.\n",
    "\n",
    "\n",
    "The syntax is `.find_all(\"tag\",{\"attribute\":\"attribute-value\"})`\n",
    "\n",
    "There are different *attributes* one could use to locate the object we want, a common attribute to use is called *class*, and in our case the object has: `class=\"property_title prominent\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the object with the name of a hotel\n",
    "soup.find(\"a\",{\"class\":\"property_title prominent\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `.text` function discussed previously to get rid of tags and attributes and keep only the *text* part, which is what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the object with the name of a hotel\n",
    "soup.find(\"a\",{\"class\":\"property_title prominent\"}).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `strip()` method to remove blank spaces in the beginning or end of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove blanks\n",
    "soup.find(\"a\",{\"class\":\"property_title prominent\"}).text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable 2: Number of reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply the exact same strategy we used for hotel names, only changing the **tag** and **attribute** that we pass to `.find`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of reviews\n",
    "soup.find(\"a\",{\"class\":\"review_count\"}).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further manipulate the *text* to make it look nicer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only want number\n",
    "soup.find(\"a\",{\"class\":\"review_count\"}).text.replace('reviews','').replace('review','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only want number\n",
    "soup.find(\"a\",{\"class\":\"review_count\"}).text.replace('reviews','').replace('review','').replace(\",\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove useless blanks\n",
    "soup.find(\"a\",{\"class\":\"review_count\"}).text.replace('reviews','').replace('review','').replace(\",\",\"\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable 3: Average rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the *average rating* of a hotel we need to do something slightly different.\n",
    "\n",
    "We start as usual, by using the `Inspect` tool in the browser. \n",
    "\n",
    "The two cells below show the copied HTML for two different hotels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "<a class=\"ui_bubble_rating bubble_50\" alt=\"5 of 5 bubbles\" data-clicksource=\"BubbleRating\" \n",
    "onmouseover=\"widgetEvCall('handlers.showReview', event, this, 514534, true);\" \n",
    "onclick=\"widgetEvCall('handlers.reviewCountOnClick', event, this);return false;\" \n",
    "data-style=\"max-width:300px;padding:16px;\" \n",
    "href=\"/Hotel_Review-g187514-d514534-Reviews-The_Pavilions_Madrid-Madrid.html#REVIEWS\" target=\"_blank\"> \n",
    "</a>\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "<a class=\"ui_bubble_rating bubble_45\" alt=\"4.5 of 5 bubbles\" data-clicksource=\"BubbleRating\" \n",
    "onmouseover=\"widgetEvCall('handlers.showReview', event, this, 190569, true);\" \n",
    "onclick=\"widgetEvCall('handlers.reviewCountOnClick', event, this);return false;\" \n",
    "data-style=\"max-width:300px;padding:16px;\" \n",
    "href=\"/Hotel_Review-g187514-d190569-Reviews-The_Westin_Palace_Madrid-Madrid.html#REVIEWS\" target=\"_blank\"> \n",
    "</a>\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the information on **rating** is in there: 4.5, 5 and so on.\n",
    "\n",
    "But this information is not rendered as **`text`**.\n",
    "\n",
    "Note the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rendered as text\n",
    "\"\"\"\n",
    "<div class=\"xxxxxxxxxx\" target=\"xxxxxxxx\"> NAME OF HOTEL</div>\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# information in the attribute value itself, there is no text at the end\n",
    "\"\"\"\n",
    "<a class=\"ui_bubble_rating bubble_45\" alt=\"4.5 of 5 bubbles\" data-clicksource=\"BubbleRating\" \n",
    "xcxxxxxxx></a>\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we cannot do: `soup.find(\"a\",{\"class\":\"ui_bubble_rating bubble_45\"}).text`\n",
    "\n",
    "There is **no text** to get, the information we need is an **attribute value**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting attribute values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: different hotels will have different *value* for the attribute *class* in that specific container:\n",
    "- ui_bubble_rating bubble_10\n",
    "- ui_bubble_rating bubble_15\n",
    "- ...\n",
    "- ...\n",
    "- ui_bubble_rating bubble_50\n",
    "\n",
    "Second: our search parameters need to be **common** across hotels because ultimately we want our code to be able to scrape information from many hotel listings (thus `soup.find(\"a\",{\"class\":\"ui_bubble_rating bubble_45\"})` won't work).\n",
    "\n",
    "**Solution:** one possible solution is to look for some other `attribute` with a *value* that is **common** across all hotels.\n",
    "\n",
    "**Remark:** this is not be the `attribute` we want to extract the value of.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "In our case we want the value of either the attribute `class` (bubble_45) or `alt` (4.5 of 5 bubbles).\n",
    "\n",
    "If we go back to the HTMLs above for two different hotels we see that `data-clicksource=\"BubbleRating\"` is a good candidate for common valued `attribute`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by passing the common valued attribute to the `find` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the common HTML in the code above\n",
    "soup.find(\"a\",{\"data-clicksource\":\"BubbleRating\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the attributes this object has with `.attrs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"a\",{\"data-clicksource\":\"BubbleRating\"}).attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need can be found either in **class** or **alt** attributes.\n",
    "\n",
    "To avoid dealing with *commas* or *dots* (e.g. 4.5), I will use **class**.\n",
    "\n",
    "The following lines of code show how to get the *value* of the **class** *attribute*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the value of class\n",
    "soup.find(\"a\",{\"data-clicksource\":\"BubbleRating\"}).attrs['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing terms like in lists\n",
    "soup.find(\"a\",{\"data-clicksource\":\"BubbleRating\"}).attrs['class'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further indexing like in lists (strings can be indexed)\n",
    "soup.find(\"a\",{\"data-clicksource\":\"BubbleRating\"}).attrs['class'][-1][-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable 4: Price\n",
    "\n",
    "Applying the same reasoning for price we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract price from the soup\n",
    "soup.find(\"div\",{\"class\":\"price autoResize\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract price from the soup\n",
    "soup.find(\"div\",{\"class\":\"price autoResize\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract price from the soup\n",
    "soup.find(\"div\",{\"class\":\"price autoResize\"}).text.replace(\"€\",\"\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know how to extract from the *soup* the variables we need from each hotel.\n",
    "\n",
    "Next, we only need to iterate over hotels and get data for each one separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `find_all` to loop over all hotels in the soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've seen, the *objects* of the webpage HTML are structured in **tag** *containers* and *attributes*.\n",
    "\n",
    "**Containers** are like broad sets constituted of smaller elements, its **attributes**.\n",
    "\n",
    "Bringing this idea to our example: **hotels** can be thought of as *containers* and its characteristics such as **name, number of reviews, etc.** are its attributes.\n",
    "\n",
    "Moreover, when an object of the website repeats itself many times, the container that holds its information also repeats itself in the HTML.\n",
    "\n",
    "Thus, one option to achieve our goal is:\n",
    "1. Look for HTML parameters that contain an entire hotel listing.\n",
    "1. Use the `find_all` on that container so that each element of our *ResultSet* object is an entire hotel listing.\n",
    "1. Loop over hotel listings, extracting on each iteration the relevant *attribute value* or *text*.\n",
    "1. At the end of each iteration save the information on a dictionary or list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `tag` of a hotel listing\n",
    "\n",
    "We go to [Tripadvisor](https://www.tripadvisor.com/Hotels-g187514-Madrid-Hotels.html) and use the *inspect* tool to find the relevant tag.\n",
    "\n",
    "We move up the branches (levels) of the **\"tag tree\"** up to the point when we notice that the entire information of a hotel listing is within that *container*, and then we right-click and select *copy element*.\n",
    "\n",
    "**Remark:** as we move the cursor over the inspect window, the items on the website are highlighted in and out indicating the object the `tag` refers to.\n",
    "\n",
    "\n",
    "\n",
    "**Hotel listing:** we notice the tag has the following initial structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "<div class=\"prw_rup prw_meta_hsx_responsive_listing ui_section listItem\" \n",
    "...........................MANY THINGS.............................\n",
    "\"\"\"; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** `<div>` is pretty common to come across and it is used to divide or section off content on a web page.\n",
    "\n",
    "We now have the `tag` that identifies each hotel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all hotels listings with find_all\n",
    "hotel_listings = soup.find_all(\"div\",{\"class\":\"prw_rup prw_meta_hsx_responsive_listing ui_section listItem\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many hotels on the page?\n",
    "len(hotel_listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, our strategy was to loop over elements of the object *hotel_listings*, extracting in each iteration the information we want of a given hotel.\n",
    "\n",
    "The code below loops over *hotel_listings* extracting hotel *names*, *number of reviews*, *average rating* and *price*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over hotel in the soup\n",
    "\n",
    "# create an empty dictionary to store the final information\n",
    "# it could also be a list, I show both just to exemplify\n",
    "hotels_info_dict = {}\n",
    "\n",
    "# find all hotel listings on the soup\n",
    "hotel_listings = soup.find_all(\"div\",{\"class\":\"prw_rup prw_meta_hsx_responsive_listing ui_section listItem\"})\n",
    "\n",
    "# loop over all hotels on the page\n",
    "# remember \"enumerate\" allows us to loop over index and value (e.g. [A,B,C] you can get (0,A),(1,B),(2,C))\n",
    "# index \"i\" will be useful for assigning new dictionary keys (entries)\n",
    "for hotel in hotel_listings:\n",
    "    \n",
    "    # take care with identation\n",
    "       \n",
    "    # name\n",
    "    name     = hotel.find(\"a\",{\"class\":\"property_title prominent\"}).text.strip()\n",
    "    \n",
    "    # number of reviews\n",
    "    reviews  = hotel.find(\"a\",{\"class\":\"review_count\"}).text.replace('reviews','').replace('review','').replace(\",\",\"\").strip()\n",
    "    \n",
    "    # average rating\n",
    "    rating   = hotel.find(\"a\",{\"data-clicksource\":\"BubbleRating\"}).attrs['class'][-1][-2:]\n",
    "    \n",
    "    # price\n",
    "    price    = hotel.find(\"div\",{\"class\":\"price autoResize\"}).text.replace(\"€\",\"\").strip()\n",
    "    \n",
    "    # before moving on to next iteration, save to dictionary\n",
    "    hotels_info_dict[name] = [reviews, rating, price]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out our dictionary to check that things make sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# information on hotels \n",
    "hotels_info_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do the same thing storing information on a python `list` instead of a `dictionary`. \n",
    "\n",
    "In the end we will have a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty list to store the final information\n",
    "hotels_info_list = []\n",
    "\n",
    "# find all hotel listings on the soup\n",
    "hotel_listings = soup.find_all(\"div\",{\"class\":\"prw_rup prw_meta_hsx_responsive_listing ui_section listItem\"})\n",
    "\n",
    "# loop over all hotels on the page\n",
    "# for lists we don't need the \"enumerate\" function (we use the append function at the end to add information)\n",
    "for hotel in hotel_listings:\n",
    "    \n",
    "    # take care with identation\n",
    "    \n",
    "    # name\n",
    "    name     = hotel.find(\"a\",{\"class\":\"property_title prominent\"}).text.strip()\n",
    "    \n",
    "    # number of reviews\n",
    "    reviews  = hotel.find(\"a\",{\"class\":\"review_count\"}).text.replace('reviews','').replace('review','').replace(\",\",\"\").strip()\n",
    "    \n",
    "    # average rating\n",
    "    rating   = hotel.find(\"a\",{\"data-clicksource\":\"BubbleRating\"}).attrs['class'][-1][-2:].strip()\n",
    "\n",
    "    # price\n",
    "    price    = hotel.find(\"div\",{\"class\":\"price autoResize\"}).text.replace(\"€\",\"\").strip()\n",
    "\n",
    "    # on each iteration .append adds information of one hotel \n",
    "    # note that we have a list of lists\n",
    "    hotels_info_list.append( [name, reviews, rating, price] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print our `list` and verify that it has the same information contained in the `dictionary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the list \n",
    "hotels_info_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!!\n",
    "\n",
    "But the idea of scraping is to allow us to extract __large amounts__ of information.\n",
    "\n",
    "Data on a few hotels only is not enough. \n",
    "\n",
    "This takes us to our next *Step*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Scale up (and adjust small issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What we did so far:__ scraped information on all hotels listed on one page.\n",
    "- More specifically, all hotels listed on the first search page of Tripadvisor hotels in Madrid (page 1).\n",
    "\n",
    "That's because we used `request.get(\"https://www.tripadvisor.com/Hotels-g187514-Madrid-Hotels.html\")`\n",
    "\n",
    "By scrolling down the page we note that there are many **more pages** with hotel listings.\n",
    "\n",
    "Luckily, we can add a simple `outer loop` to our code in order to scrape more hotels (from different page numbers).\n",
    "\n",
    "The basic idea is to repeat what we did in this last section for each page number 1, 2, 3, .... up to the page we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping over pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we go back to [Tripadvisor](https://www.tripadvisor.com/Hotels-g187514-Madrid-Hotels.html) we realize that as we move across search pages a **pattern** emerges.\n",
    "\n",
    "Page 1:  https://www.tripadvisor.com/Hotels-g187514-Madrid-Hotels.html\n",
    "\n",
    "Page 2:  https://www.tripadvisor.com/Hotels-g187514-oa30-Madrid-Hotels.html\n",
    "\n",
    "Page 3:  https://www.tripadvisor.com/Hotels-g187514-oa60-Madrid-Hotels.html\n",
    "\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "\n",
    "Page 52: https://www.tripadvisor.com/Hotels-g187514-oa1530-Madrid-Hotels.html\n",
    "\n",
    "Page 53: https://www.tripadvisor.com/Hotels-g187514-oa1560-Madrid-Hotels.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The pattern across URLs\n",
    "\n",
    "URLs are the same except for an additional term: `oaNUMBER` in between dashes.\n",
    "\n",
    "Where `NUMBER` increases by 30 for each subsequent page.\n",
    "\n",
    "In general, if we want to access page `n`, the number that goes into the URL is `(n-1)*30`.\n",
    "\n",
    "**Notes (good):** \n",
    "- Patters similar to this one happen in other websites as well.\n",
    "- For example on [Craigslist](https://newyork.craigslist.org/search/cta), we can see a similar feature.\n",
    "- The term I am calling `NUMBER` relates to the number of listings per page.\n",
    "\n",
    "**Notes (not so good):** \n",
    "- However, it doesn't always work.\n",
    "- For example, [Linkedin](https://www.linkedin.com/jobs/jobs-in-madrid?trk=homepage-basic_intent-module-jobs&position=1&pageNum=0) has what is called an *infinite scrolling* feature (show on page).\n",
    "- When you encounter scenarios such as this one, you may need more than just the `requests` library.\n",
    "- And a good option might be [Selenium](https://selenium-python.readthedocs.io/), a tool that allows you to interact with the page (click on items, scroll down, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping over pages\n",
    "\n",
    "There are many ways to add an outer loop to our previous code.\n",
    "\n",
    "Bur regardless of the way we do it, we go from **wide to narrow**.\n",
    "\n",
    "That is:\n",
    "- Loop over pages;\n",
    "    - On each page find all hotels and loop over them;\n",
    "        - For each hotel, obtain the information we want and save;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One option to get the numbers we need for updating URLs, is to use the `range` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of how to get number that iterate from page 1 through page 5\n",
    "\n",
    "# range (start, end, step)\n",
    "for x in range(0, 121, 30):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to transform these numbers into a full URL we can manipulate strings.\n",
    "\n",
    "Note that when we use the number zero, the request directs us to the search page number 1, thus we don't need to create a separate code for the first page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating all the URLs for different page numbers\n",
    "for x in range(0,91,30):\n",
    "    url = \"https://www.tripadvisor.com/Hotels-g187514-oa\" + str(x) + \"-Madrid-Hotels.html\"\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell exemplifies how we can scrape hotels from more than one page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    " \n",
    "# extra imports usually useful with scraping\n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "### INPUT: choose number of pages to scrape \n",
    "n_pages = 3\n",
    "\n",
    "# this just controls the time it takes the code to run\n",
    "start_time = time.time()\n",
    "\n",
    "# empty list to store the final information\n",
    "hotels_info = []\n",
    "\n",
    "# loop over search pages\n",
    "for x in range(0,  ((n_pages-1)*30)+1   , 30):\n",
    "    \n",
    "    # update URL\n",
    "    url = \"https://www.tripadvisor.com/Hotels-g187514-oa\" + str(x) + \"-Madrid-Hotels.html\"    \n",
    "\n",
    "    # for each url, send request\n",
    "    result = requests.get(url)\n",
    "\n",
    "    # prevent disrupting the activity of the website\n",
    "    # before moving on, the code waits a random number of seconds between 1 and 3\n",
    "    time.sleep(randint(1,3))\n",
    "\n",
    "    # parse the HTML content of that page\n",
    "    soup = BeautifulSoup(result.content, 'html.parser')\n",
    "\n",
    "    # find all hotel listings on the soup\n",
    "    hotel_listings = soup.find_all(\"div\",{\"class\":\"prw_rup prw_meta_hsx_responsive_listing ui_section listItem\"})\n",
    "\n",
    "    # loop over all hotels on the page\n",
    "    for hotel in hotel_listings:\n",
    "\n",
    "        # take care with identation\n",
    "\n",
    "        # each item below reproduces what we did previously\n",
    "\n",
    "        # name\n",
    "        name     = hotel.find(\"a\",{\"class\":\"property_title prominent\"}).text.strip()\n",
    "\n",
    "        # number of reviews\n",
    "        reviews  = hotel.find(\"a\",{\"class\":\"review_count\"}).text.replace('reviews','').replace('review','').replace(\",\",\"\").strip()\n",
    "\n",
    "        # average rating\n",
    "        rating   = hotel.find(\"a\",{\"data-clicksource\":\"BubbleRating\"}).attrs['class'][-1][-2:].strip()\n",
    "\n",
    "        # price\n",
    "        price    = hotel.find(\"div\",{\"class\":\"price autoResize\"}).text.replace(\"€\",\"\").strip()\n",
    "\n",
    "        # on each iteration .append adds information of one hotel \n",
    "        # note that we have a list of lists\n",
    "        hotels_info.append([name, reviews, rating, price])\n",
    "\n",
    "\n",
    "# print time it took to finish\n",
    "time_elased = time.time() - start_time # now - minus when it started\n",
    "minutes = int( (time_elased)/60 )      # entire minutes\n",
    "seconds = time_elased % 60             # % is remainder operator \n",
    "print(\"--- %.0f minutes and %.0f seconds to scrape %.0f listings ---\" % ( minutes,seconds,len(hotels_info)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can check our list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "hotels_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping over cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another dimension over which we can increase the number of hotels we get is the location/city.\n",
    "\n",
    "We could do it for as many cities as we want, but the time to complete the scrape would increase.\n",
    "\n",
    "Here, just for the sake of our example, I will do it for three cities: *Madrid, Lisbon, and São João del Rei*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### URL of different cities\n",
    "\n",
    "Searching on [Tripadvisor](https://www.tripadvisor.com), we see that the URLs for hotels in these cities are (these are for search page number 2):\n",
    "- Madrid: https://www.tripadvisor.com/Hotels-g187514-Madrid-Hotels.html\n",
    "- Lisbon: https://www.tripadvisor.com/Hotels-g189158-Lisbon_Lisbon_District_Central_Portugal-Hotels.html\n",
    "- Sao Joao del Rei: https://www.tripadvisor.com/Hotels-g737099-Sao_Joao_del_Rei_State_of_Minas_Gerais-Hotels.html\n",
    "\n",
    "We note that across cities, URLs vary in terms of:\n",
    "- A six digit number as in `gXXXXXX`.\n",
    "- And the written description of the place, for example `Lisbon_Lisbon_District_Central_Portugal`.\n",
    "\n",
    "Knowing what we already know about `loops`, there are many ways to construct a loop over cities and page numbers.\n",
    "\n",
    "Below is one possibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of lists to capture city code and name that go into the Tripadvisor url\n",
    "cities_url = [ ['g187514','Madrid']                                   , \n",
    "               ['g189158','Lisbon_Lisbon_District_Central_Portugal']  ,\n",
    "               ['g737099','Sao_Joao_del_Rei_State_of_Minas_Gerais']                               ] \n",
    "\n",
    "# print first two pages of each city just to illustrate\n",
    "n_pages = 2\n",
    "\n",
    "#\n",
    "for city in cities_url:\n",
    "    for x in range(0, ((n_pages-1)*30)+1 ,30):\n",
    "        # the URL in the format above\n",
    "        url = \"https://www.tripadvisor.com/Hotels-\" + city[0] + \"-oa\" + str(x) + \"-\" + city[1] + \"-Hotels.html\"\n",
    "        print(url)\n",
    "        # the city name to be saved in the final spreadsheet\n",
    "        city_code = city[1][0:3].upper()\n",
    "        print(city_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many pages do we want to scrape?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is up to the researcher, depends on the case.\n",
    "\n",
    "**Notes:** \n",
    "- When scraping from platforms that aggregate businesses/sellers (e.g. Tripadvisor, Yelp, Amazon, etc.), the last ones to appear on the search usually have little information.\n",
    "- And since scraping takes time, we usually want to take a look at the website first to check if all data is relevant. \n",
    "\n",
    "Check the last pages of hotel listings to verify that there is not much usefulness in scraping them.\n",
    "\n",
    "In any case, the amount of information one wants to scrape will depend on the application and the trade-off between execution time and amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cities with different number of pages\n",
    "\n",
    "We already know how to scrape *X* number of pages per city.\n",
    "\n",
    "But once we start dealing with cities with a very different number of hotels, a given page number may not be general enough to our purposes. \n",
    "\n",
    "**Example**: \n",
    "- SJDR has very few hotels listed (only 3 pages).\n",
    "- So if we set our code to scrape 4 (or more) pages per city we would have problems.\n",
    "- Passing to the `request.get(url)` a page number larger than the real maximum number of pages will either result in error or wasted time (it loads the first page and we scrape the same hotels repeatedly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A natural solution\n",
    "\n",
    "We can add to our code a feature to identify the number of search pages a city has and use this as a guide for how many pages we want to scrape for that city.\n",
    "\n",
    "The code below shows one way to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of lists to capture city code and name that go into the Tripadvisor url\n",
    "cities_url = [ ['g187514','Madrid']                                   , \n",
    "               ['g189158','Lisbon_Lisbon_District_Central_Portugal']  ,\n",
    "               ['g737099','Sao_Joao_del_Rei_State_of_Minas_Gerais']                               ] \n",
    "\n",
    "#\n",
    "for city in cities_url:\n",
    "\n",
    "    # use first page to look for number of pages that city has\n",
    "    url = \"https://www.tripadvisor.com/Hotels-\" + city[0] + \"-\" + city[1] + \"-Hotels.html\"\n",
    "    \n",
    "    # send request\n",
    "    result = requests.get(url)\n",
    "    \n",
    "    # parse the HTML content of that page\n",
    "    soup = BeautifulSoup(result.content, 'html.parser')\n",
    "    \n",
    "    # identify number of pages\n",
    "    n_pages = int(soup.find(\"div\",{\"class\":\"unified ui_pagination standard_pagination ui_section listFooter\"}).attrs['data-numpages'].strip())\n",
    "    \n",
    "    # Print on screen to show that the code does what we want\n",
    "    n_on_url = ((n_pages-1)*30)\n",
    "    url = \"https://www.tripadvisor.com/Hotels-\" + city[0] + \"-oa\" + str(n_on_url) + \"-\" + city[1] + \"-Hotels.html\"\n",
    "    city_code = city[1][0:3].upper()\n",
    "    print(\"For city code %s we can scrape up to search page %s, with url:\\n %s\" % (city_code, n_pages, url) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it all together \n",
    "\n",
    "In the cell below I put together our previous code with the last two outer loops that scale up our code.\n",
    "\n",
    "With what have so far we can scrape all hotels from all pages that each of the cities has available.\n",
    "\n",
    "But this would take several minutes and just to exemplify here in class, I will add the following modification:\n",
    "- Check the number of pages a city has.\n",
    "- If this number is 3 or below, we scrape all (SAO).\n",
    "- If it is greater than 3, we only scrape the first 3 pages for that city (MAD, LIS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    " \n",
    "# extra imports usually useful with scraping\n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "# this just controls the time it takes the code to run\n",
    "start_time = time.time()\n",
    "\n",
    "# empty list to store the final information\n",
    "hotels_info = []\n",
    "\n",
    "# list of lists to capture city code and name that go into the Tripadvisor url\n",
    "cities_url = [ ['g187514','Madrid']                                   , \n",
    "               ['g189158','Lisbon_Lisbon_District_Central_Portugal']  ,\n",
    "               ['g737099','Sao_Joao_del_Rei_State_of_Minas_Gerais']                               ] \n",
    "\n",
    "# loop over cities\n",
    "for city in cities_url:\n",
    "    \n",
    "    # store city code to save as variable at the end\n",
    "    city_code = city[1][0:3].upper()\n",
    "    \n",
    "    # use first page to look for number of pages that city has\n",
    "    url = \"https://www.tripadvisor.com/Hotels-\" + city[0] + \"-\" + city[1] + \"-Hotels.html\"\n",
    "    # send request\n",
    "    result = requests.get(url)\n",
    "    # parse the HTML content of that page\n",
    "    soup = BeautifulSoup(result.content, 'html.parser')\n",
    "    \n",
    "    # identify number of pages\n",
    "    n_pages = int(soup.find(\"div\",{\"class\":\"unified ui_pagination standard_pagination ui_section listFooter\"}).attrs['data-numpages'].strip())\n",
    "    # to save time we only scrape a max of 3 pages per city\n",
    "    # we only need to remove the two lines below in order to scrape all hotels of each city\n",
    "    if n_pages>3:\n",
    "        n_pages=3\n",
    "    \n",
    "    # loop over search pages\n",
    "    for x in range(0, ((n_pages-1)*30)+1 ,30):\n",
    "        \n",
    "        # the URL in the format above\n",
    "        url = \"https://www.tripadvisor.com/Hotels-\" + city[0] + \"-oa\" + str(x) + \"-\" + city[1] + \"-Hotels.html\"\n",
    "        \n",
    "        # for each url, send request\n",
    "        result = requests.get(url)\n",
    "\n",
    "        # prevent disrupting the activity of the website: waits a random number of seconds between 1 and 3\n",
    "        time.sleep(randint(1,3))\n",
    "\n",
    "        # parse the HTML content of that page\n",
    "        soup = BeautifulSoup(result.content, 'html.parser')\n",
    "\n",
    "        # find all hotel listings on the soup\n",
    "        hotel_listings = soup.find_all(\"div\",{\"class\":\"prw_rup prw_meta_hsx_responsive_listing ui_section listItem\"})\n",
    "\n",
    "        # loop over all hotels on the page\n",
    "        for hotel in hotel_listings:\n",
    "\n",
    "            # name\n",
    "            name     = hotel.find(\"a\",{\"class\":\"property_title prominent\"}).text.strip()\n",
    "\n",
    "            # number of reviews\n",
    "            reviews  = hotel.find(\"a\",{\"class\":\"review_count\"}).text.replace('reviews','').replace('review','').replace(\",\",\"\").strip()\n",
    "            \n",
    "            # average rating\n",
    "            rating   = hotel.find(\"a\",{\"data-clicksource\":\"BubbleRating\"}).attrs['class'][-1][-2:].strip()\n",
    "            \n",
    "            # price\n",
    "            price    = hotel.find(\"div\",{\"class\":\"price autoResize\"}).text.replace(\"€\",\"\").strip()\n",
    "\n",
    "            # on each iteration .append adds information of one hotel \n",
    "            hotels_info.append([name, reviews, rating, price, city_code])\n",
    "            \n",
    "# print time it took to finish\n",
    "time_elased = time.time() - start_time # now - minus when it started\n",
    "minutes = int( (time_elased)/60 )      # entire minutes\n",
    "seconds = time_elased % 60             # % is remainder operator \n",
    "print(\"--- %.0f minutes and %.0f seconds to scrape %.0f hotel listings ---\" % ( minutes,seconds,len(hotels_info)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an **error** message. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final adjustments (1): handling missing information\n",
    "\n",
    "It is common to have errors that only show up when you scale up the code.\n",
    "\n",
    "It had worked before for pages 1 through 3 in Madrid, so the problem must be somewhere else.\n",
    "\n",
    "The *error* is: `'NoneType' object has no attribute 'attrs'`.\n",
    "\n",
    "Problems similar to this one are pretty common with scraping and they have to do with missing information.\n",
    "\n",
    "Let's have a look at the objects we had going right before the error ocurred.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our URL when the error ocurred was\n",
    "url # the problem was in the city Sao Joao del Rei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name when error occurred\n",
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you navigate to the Tripadvisor page of this hotel you'll notice it has ZERO reviews.\n",
    "\n",
    "Understably, hotels with **zero reviews** don't have the HTML tag for **ratings**:\n",
    "- They still have the HTML for reviews, for which the text is \"0\".\n",
    "- But our find method delivers a `None` object when it searches for ratings (whenever the parameters - tag and attribute - of a `.find()` method are not found in the source html code, the output is a `None` object).\n",
    "\n",
    "We can see this clearly by asking for each object separetely and priting the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"class\":\"property_title prominent\" and \"class\":\"review_count\" can be found\n",
    "\n",
    "# name\n",
    "hotel_name     = hotel.find(\"a\",{\"class\":\"property_title prominent\"})\n",
    "\n",
    "# number of reviews\n",
    "reviews        = hotel.find(\"a\",{\"class\":\"review_count\"})\n",
    "\n",
    "# average rating\n",
    "rating         = hotel.find(\"a\",{\"data-clicksource\":\"BubbleRating\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name is fine\n",
    "print(hotel_name, \"\\n\")\n",
    "print(hotel_name.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of reviews is fine\n",
    "print(reviews, \"\\n\")\n",
    "print(reviews.text.replace('reviews','').replace('review','').replace(\",\",\"\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem is here\n",
    "print(rating, \"\\n\")\n",
    "print(rating.attrs['class'][-1][-2:].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem is not exclusive of attrs; with .text or any other method the problem would persist\n",
    "print(rating, \"\\n\")\n",
    "print(rating.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** whenever the `find` method delivers a `None` object, we will get an **error** if we apply any `.function` on it.\n",
    "\n",
    "### Solution\n",
    "\n",
    "As we've seen above, when the `find` method delivers `None` it means that for that listing, this piece of information is unavailable.\n",
    "\n",
    "Thus, it makes sense to assign a *missing* or *empty* for that variable (simply `x = \"\"`).\n",
    "\n",
    "Below is one way to adapt our code to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# like this we get no errors and assing missing (empty) when variable does exists\n",
    "rating_tag   = hotel.find(\"a\",{\"data-clicksource\":\"BubbleRating\"})\n",
    "rating       = rating_tag.attrs['class'][-1][-2:].strip() if rating_tag else \"\"\n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarks:** \n",
    "- It is good practice to adopt the structure above to all variables.\n",
    "- That's because it is not uncommon to have one item (e.g. hotel listing) with missing tag for one variable only (e.g. price).\n",
    "- If we don't follow the structure above the whole code will brake because of one item only.\n",
    "- **Examples:** \n",
    "    - A job posting missing the salary field;\n",
    "    - A rental listing missing the square meters field;\n",
    "    - Etc, ect....\n",
    "\n",
    "The cell below adapts the code to handle missing information and it should run all the way through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    " \n",
    "# extra imports usually useful with scraping\n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "# this just controls the time it takes the code to run\n",
    "start_time = time.time()\n",
    "\n",
    "# empty list to store the final information\n",
    "hotels_info = []\n",
    "\n",
    "# list of lists to capture city code and name that go into the Tripadvisor url\n",
    "cities_url = [ ['g187514','Madrid']                                   , \n",
    "               ['g189158','Lisbon_Lisbon_District_Central_Portugal']  ,\n",
    "               ['g737099','Sao_Joao_del_Rei_State_of_Minas_Gerais']                               ] \n",
    "\n",
    "# loop over cities\n",
    "for city in cities_url:\n",
    "    \n",
    "    # store city code to save as variable at the end\n",
    "    city_code = city[1][0:3].upper()\n",
    "    \n",
    "    # use first page to look for number of pages that city has\n",
    "    url = \"https://www.tripadvisor.com/Hotels-\" + city[0] + \"-\" + city[1] + \"-Hotels.html\"\n",
    "    \n",
    "    # send request\n",
    "    result = requests.get(url)\n",
    "     \n",
    "    # parse the HTML content of that page\n",
    "    soup = BeautifulSoup(result.content, 'html.parser')\n",
    "    \n",
    "    # identify number of pages\n",
    "    n_pages = int(soup.find(\"div\",{\"class\":\"unified ui_pagination standard_pagination ui_section listFooter\"}).attrs['data-numpages'].strip())\n",
    "    \n",
    "    # to save time we only scrape a max of 4 pages per city\n",
    "    # we only need to remove the two lines below in order to scrape all hotels of each city\n",
    "    if n_pages>3:\n",
    "        n_pages=3\n",
    "    \n",
    "    # loop over search pages\n",
    "    for x in range(0, ((n_pages-1)*30)+1 ,30):\n",
    "                \n",
    "        # the URL in the format above\n",
    "        url = \"https://www.tripadvisor.com/Hotels-\" + city[0] + \"-oa\" + str(x) + \"-\" + city[1] + \"-Hotels.html\"\n",
    "        \n",
    "        # for each url, send request\n",
    "        result = requests.get(url)\n",
    "\n",
    "        # prevent disrupting the activity of the website: waits a random number of seconds between 1 and 3\n",
    "        time.sleep(randint(1,3))\n",
    "\n",
    "        # parse the HTML content of that page\n",
    "        soup = BeautifulSoup(result.content, 'html.parser')\n",
    "\n",
    "        # find all hotel listings on the soup\n",
    "        hotel_listings = soup.find_all(\"div\",{\"class\":\"prw_rup prw_meta_hsx_responsive_listing ui_section listItem\"})\n",
    "\n",
    "        # loop over all hotels on the page\n",
    "        for hotel in hotel_listings:\n",
    "\n",
    "            # name\n",
    "            name_tag    = hotel.find(\"a\",{\"class\":\"property_title prominent\"})\n",
    "            name        = name_tag.text.strip() if name_tag else \"\"\n",
    "            \n",
    "            # number of reviews\n",
    "            reviews_tag = hotel.find(\"a\",{\"class\":\"review_count\"})\n",
    "            reviews     = reviews_tag.text.replace('reviews','').replace('review','').replace(\",\",\"\").strip() if reviews_tag else \"\"\n",
    "\n",
    "            # average rating\n",
    "            rating_tag  = hotel.find(\"a\",{\"data-clicksource\":\"BubbleRating\"})\n",
    "            rating      = rating_tag.attrs['class'][-1][-2:].strip() if rating_tag else \"\"\n",
    "\n",
    "            # price\n",
    "            price_tag   = hotel.find(\"div\",{\"class\":\"price autoResize\"})\n",
    "            price       = price_tag.text.replace(\"€\",\"\").strip() if price_tag else \"\"\n",
    "\n",
    "            # on each iteration .append adds information of one hotel \n",
    "            hotels_info.append([name, reviews, rating, price, city_code])\n",
    "            \n",
    "# print time it took to finish\n",
    "time_elased = time.time() - start_time # now - minus when it started\n",
    "minutes = int( (time_elased)/60 )      # entire minutes\n",
    "seconds = time_elased % 60             # % is remainder operator \n",
    "print(\"--- %.0f minutes and %.0f seconds to scrape %.0f hotel listings ---\" % ( minutes,seconds,len(hotels_info)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see our final list\n",
    "hotels_info[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does the number of hotels scraped make sense?\n",
    "len(hotels_info) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final adjustment 2: repeated listings\n",
    "\n",
    "Everything looks good, but we can still add one last adjustment.\n",
    "\n",
    "In theory, we should be getting unique hotel listings:\n",
    "- We are looping over different page numbers of different cities.\n",
    "\n",
    "But the lines of code below suggest that we are getting repeated listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many listings did we scrape?\n",
    "len(hotels_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I remove duplicate entries using the following rule:\n",
    "- If a listing has the same *name, number of reviews, average rating, price and city*, then I consider it a duplicate.\n",
    "\n",
    "**Note:** \n",
    "- This solution is not **foolproof** (possible to have same name in two different addresses in the same city).\n",
    "- But unlikely to have same number of reviews and average rating as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicates  \n",
    "hotels_info_unique = []\n",
    "#\n",
    "for i in hotels_info: \n",
    "    if i not in hotels_info_unique: \n",
    "        hotels_info_unique.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listings remaining\n",
    "len(hotels_info_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why there may be repeated listings?\n",
    "\n",
    "Two reasons:\n",
    "1. Sponsored listings.\n",
    "1. Search pages are dynamic and rankings change constantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Export the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our list called *hotels_info* has everything we wanted, but to conduct analysis we usually want to have data in a spreadsheet format.\n",
    "\n",
    "The standard way to see data in spreadsheet style in Python is to use [Pandas](https://pandas.pydata.org/).\n",
    "\n",
    "As usual, we `import` before using it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usual way to import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform our list into a Pandas dataframe object\n",
    "df = pd.DataFrame(hotels_info_unique, columns=['hotel_name', 'n_reviews', \n",
    "                                               'rating', 'price', 'city'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's how a spreadsheet looks like if use want to conduct your analysis in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to quickly inspect data\n",
    "df.head() # or \n",
    "#df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we could carry out some quick visual analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to nummeric (we collected them as strings)\n",
    "df['rating']    = pd.to_numeric(df['rating'])/10 # to scale from 1 to 5\n",
    "df['n_reviews'] = pd.to_numeric(df['n_reviews'])\n",
    "df['price']     = pd.to_numeric(df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over hotels\n",
    "print(\"Average number of reviews is: \", \"{:.2f}\".format(df['n_reviews'].mean()))\n",
    "print(\"Average rating is: \",            \"{:.2f}\".format(df['rating'].mean()))\n",
    "print(\"Average price is: \",            \"{:.2f}\".format(df['price'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average by city\n",
    "df.groupby('city').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick visual inspection of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual inspection of one distribution\n",
    "\n",
    "# import plot library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data for each histogram\n",
    "mad = df.loc[ df.city=='MAD'   , 'n_reviews']\n",
    "\n",
    "# that's how to start a figure in matplotlib\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "#\n",
    "kwargs = dict(alpha=0.6)\n",
    "\n",
    "#\n",
    "ax.hist(mad, **kwargs, color='b')\n",
    "plt.gca().set(title='Histogram of Number of Reviews for Hotels in Madrid (frequency)', ylabel='Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual inspection of two distributions\n",
    "\n",
    "# import plot library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data for each histogram\n",
    "lis = df.loc[(df.city=='LIS') & (df.price<500)    , 'price']\n",
    "mad = df.loc[(df.city=='MAD')  & (df.price<500)    , 'price']\n",
    "\n",
    "# that's how to start a figure in matplotlib\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "#\n",
    "kwargs = dict(alpha=0.6, bins=12)\n",
    "\n",
    "#\n",
    "ax.hist(mad, **kwargs, color='b', label='Madrid', density=True)\n",
    "ax.hist(lis, **kwargs, color='g', label='Lisbon', density=True)\n",
    "plt.gca().set(title='Histogram of Hotel Prices by City (density)', ylabel='Density')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# that's how to start a figure in matplotlib\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "\n",
    "\n",
    "ax = sns.boxplot(x=\"rating\", y=\"price\", \n",
    "            data=df.loc[(df.city=='LIS')  & (df.n_reviews>200)]\n",
    "            , showfliers = False);\n",
    "\n",
    "ax.set_xlabel(\"Rating\", size=13);\n",
    "ax.set_ylabel(\"Price\", size=13);\n",
    "ax.set_title(\"Prices as a function of average ratings for hotels in Lisbon\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more things we could do with the data, but that's for another course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need to do is to export the data to a standard format.\n",
    "\n",
    "That way, you would have the data safely stored and could analyze later on another software.\n",
    "\n",
    "The standard way to export a `pandas` dataframe to `csv` is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the dataframe as csv in the same folder where the notebook is running\n",
    "df.to_csv('hotel_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to any chosen path\n",
    "path = \"/Users/cayrua/Desktop/\"\n",
    "file_name = \"hotel_reviews.csv\"\n",
    "\n",
    "df.to_csv(path + file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you work on Windows, remember to use either `\\\\` or `r` before the *path*.\n",
    "\n",
    "For example, like this:\n",
    "\n",
    "    r\"C:\\Users\\c-chav30\\Documents\\hotel_reviews.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can navigate to where we saved the file and open it on Excel just to inspect if things look good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entire code in one cell\n",
    "\n",
    "Below is our final scraping code in a single cell.\n",
    "\n",
    "You can play around with the number of pages per city you want to scrape:\n",
    "- All pages, a fixed number, half of the total, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    " \n",
    "# extra imports usually useful with scraping\n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "# max pages per city\n",
    "max_pages = 100\n",
    "\n",
    "\n",
    "# this just controls the time it takes the code to run\n",
    "start_time = time.time()\n",
    "\n",
    "# empty list to store the final information\n",
    "hotels_info = []\n",
    "\n",
    "# list of lists to capture city code and name that go into the Tripadvisor url\n",
    "cities_url = [ ['g187514','Madrid']                                   , \n",
    "               ['g189158','Lisbon_Lisbon_District_Central_Portugal']  ,\n",
    "               ['g737099','Sao_Joao_del_Rei_State_of_Minas_Gerais']                               ] \n",
    "\n",
    "# loop over cities\n",
    "for city in cities_url:\n",
    "    \n",
    "    # store city code to save as variable at the end\n",
    "    city_code = city[1][0:3].upper()\n",
    "    \n",
    "    # use first page to look for number of pages that city has\n",
    "    url = \"https://www.tripadvisor.com/Hotels-\" + city[0] + \"-\" + city[1] + \"-Hotels.html\"\n",
    "    \n",
    "    # send request\n",
    "    result = requests.get(url)\n",
    "     \n",
    "    # parse the HTML content of that page\n",
    "    soup = BeautifulSoup(result.content, 'html.parser')\n",
    "    \n",
    "    # identify number of pages\n",
    "    n_pages = int(soup.find(\"div\",{\"class\":\"unified ui_pagination standard_pagination ui_section listFooter\"}).attrs['data-numpages'].strip())\n",
    "    \n",
    "    # to save time we only scrape a max of 4 pages per city\n",
    "    # we only need to remove the two lines below in order to scrape all hotels of each city\n",
    "    if n_pages>max_pages:\n",
    "        n_pages=max_pages\n",
    "    \n",
    "    # loop over search pages\n",
    "    for x in range(0, ((n_pages-1)*30)+1 ,30):\n",
    "                \n",
    "        # the URL in the format above\n",
    "        url = \"https://www.tripadvisor.com/Hotels-\" + city[0] + \"-oa\" + str(x) + \"-\" + city[1] + \"-Hotels.html\"\n",
    "        \n",
    "        # for each url, send request\n",
    "        result = requests.get(url)\n",
    "\n",
    "        # prevent disrupting the activity of the website: waits a random number of seconds between 1 and 3\n",
    "        time.sleep(randint(1,3))\n",
    "\n",
    "        # parse the HTML content of that page\n",
    "        soup = BeautifulSoup(result.content, 'html.parser')\n",
    "\n",
    "        # find all hotel listings on the soup\n",
    "        hotel_listings = soup.find_all(\"div\",{\"class\":\"prw_rup prw_meta_hsx_responsive_listing ui_section listItem\"})\n",
    "\n",
    "        # loop over all hotels on the page\n",
    "        for hotel in hotel_listings:\n",
    "\n",
    "            # name\n",
    "            name_tag    = hotel.find(\"a\",{\"class\":\"property_title prominent\"})\n",
    "            name        = name_tag.text.strip() if name_tag else \"\"\n",
    "            \n",
    "            # number of reviews\n",
    "            reviews_tag = hotel.find(\"a\",{\"class\":\"review_count\"})\n",
    "            reviews     = reviews_tag.text.replace('reviews','').replace('review','').replace(\",\",\"\").strip() if reviews_tag else \"\"\n",
    "\n",
    "            # average rating\n",
    "            rating_tag  = hotel.find(\"a\",{\"data-clicksource\":\"BubbleRating\"})\n",
    "            rating      = rating_tag.attrs['class'][-1][-2:].strip() if rating_tag else \"\"\n",
    "\n",
    "            # price\n",
    "            price_tag   = hotel.find(\"div\",{\"class\":\"price autoResize\"})\n",
    "            price       = price_tag.text.replace(\"€\",\"\").strip() if price_tag else \"\"\n",
    "\n",
    "            # on each iteration .append adds information of one hotel \n",
    "            hotels_info.append([name, reviews, rating, price, city_code])\n",
    "\n",
    "\n",
    "# removing duplicates  \n",
    "hotels_info_unique = []\n",
    "#\n",
    "for i in hotels_info: \n",
    "    if i not in hotels_info_unique: \n",
    "        hotels_info_unique.append(i)\n",
    "\n",
    "        \n",
    "# Export as csv\n",
    "\n",
    "# 1. to dataframe\n",
    "# transform our list into a Pandas dataframe object\n",
    "df = pd.DataFrame(hotels_info_unique, columns=['hotel_name', 'n_reviews', 'rating', 'price', 'city'] )\n",
    "# 2. to csv\n",
    "df.to_csv('/Users/cayrua/Desktop/hotel_reviews_full.csv', index=False)\n",
    "\n",
    "# print time it took to finish\n",
    "time_elased = time.time() - start_time # now - minus when it started\n",
    "minutes = int( (time_elased)/60 )      # entire minutes\n",
    "seconds = time_elased % 60             # % is remainder operator \n",
    "print(\"--- %.0f minutes and %.0f seconds to scrape %.0f hotel listings, %.0f of which were unique  ---\" \n",
    "      % ( minutes, seconds, len(hotels_info),len(hotels_info_unique) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  }
 ],
 "metadata": {
  "date": 1592451373.6478696,
  "filename": "about_py.rst",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "next_doc": {
   "link": "getting_started",
   "title": "Setting up Your Python Environment"
  },
  "prev_doc": {
   "link": "index_learning_python",
   "title": "Introduction to Python"
  },
  "title": "About Python"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
